<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>On the overconfidence of modern neural networks</title>
  <meta name="description" content="On the overconfidence of modern neural networks. This is the title of the coursework I did with a fellow student at the University of Edinburgh. (PDF: Part 1...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://www.treszkai.com/blog/overconfidence">
  <link rel="alternate" type="application/rss+xml" title="Laszlo Treszkai" href="/feed.xml"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>On the overconfidence of modern neural networks | Laszlo Treszkai</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="On the overconfidence of modern neural networks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Evaluating various methods to improve the calibration of deep neural networks." />
<meta property="og:description" content="Evaluating various methods to improve the calibration of deep neural networks." />
<link rel="canonical" href="https://www.treszkai.com/blog/overconfidence" />
<meta property="og:url" content="https://www.treszkai.com/blog/overconfidence" />
<meta property="og:site_name" content="Laszlo Treszkai" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-09-26T00:00:00+02:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.treszkai.com/blog/overconfidence"},"description":"Evaluating various methods to improve the calibration of deep neural networks.","@type":"BlogPosting","headline":"On the overconfidence of modern neural networks","dateModified":"2019-09-26T00:00:00+02:00","datePublished":"2019-09-26T00:00:00+02:00","url":"https://www.treszkai.com/blog/overconfidence","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://www.treszkai.com/feed.xml" title="Laszlo Treszkai" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-114915944-1', 'auto');
  ga('send', 'pageview');
}
</script>
  


</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><span class="site-title"><a rel="author" href="/">Laszlo Treszkai</a></span><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About me</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">On the overconfidence of modern neural networks</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-09-26T00:00:00+02:00" itemprop="datePublished">26 Sep. 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><em>On the overconfidence of modern neural networks</em>. This is the title of the coursework I did with a fellow student at the University of Edinburgh. (PDF: <a href="mlp-cw3.pdf">Part 1</a>, <a href="mlp-cw4.pdf">Part 2</a>.)</p>

<p>Our topic was influenced by a previous study, titled <em>On Calibration of Modern Neural Networks</em> <a class="citation" href="#Guo2017-calibration">(Guo, Pleiss, Sun, &amp; Weinberger, 2017)</a>.</p>

<p>Applications of uncertainty estimation include threshold-based outlier detection, active learning, uncertainty-driven exploration of reinforcement learning, or certain safety-critical applications.</p>

<h2 id="what-is-uncertainty">What is uncertainty?</h2>

<p>No computer vision system is perfect, so an image classification algorithm sometimes identifies people as not-people, or not-people as people.
While we usually care about the class with the highest output (the “most likely” class), we can treat the softmax outputs of a classifier as uncertainty estimates.
(After all, that is how we trained a model when treating the softmax outputs of a classifier as a probability distribution, and minimizing the negative log likelihood of the model given the data.)
For example, out of 1000 classifications made with an output of 0.8, approximately 800 should be correct <em>if the system is well-calibrated</em>.</p>

<p><img src="yolo.png" alt="Example output of a YOLO object detection network" /></p>

<p>(Example output of a YOLO object detection network, with the probability estimates. Image source: <a href="https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/">Analytics Vidhya</a>.)</p>

<p>Ideally, we want our system to be 100% correct, but we rarely have access to an all-knowing Oracle. In cases where it is hard to distinguish between two categories (like on the cat-dog below) we want the uncertainties to be well-calibrated, so that predictions are neither overly confident nor insufficiently confident.</p>

<p><img src="catdog.jpeg" alt="" /></p>

<p>(Image source: Google Brain)</p>

<h2 id="our-results">Our results</h2>

<h3 id="interim-report">Interim report</h3>

<p><a href="mlp-cw3.pdf">Link to report (PDF)</a></p>

<p>Our initial experiments showed that our baseline model is already well-calibrated when trained on the EMNIST By-Class dataset.
Calibration worsened when we used only a subset of the training set.
We found that increasing regularization increases calibration, but too much regularization leads to a decrease in both accuracy and calibration. (See figure below.)
This contradicts the findings of <a class="citation" href="#Guo2017-calibration">(Guo, Pleiss, Sun, &amp; Weinberger, 2017, sec. 3)</a>, who found that model calibration can improve by increasing the weight decay constant, well after the model achieves minimum classification accuracy.
One of our main findings is that cross-entropy error is not a good indicator of model calibration.</p>

<p><img src="mlp-cw3-fig5.png" alt="Figure 5 of our interim report." /></p>

<p>(ECE: expected calibration error. The lower the better.)</p>

<h3 id="final-report">Final report</h3>

<p><a href="mlp-cw4.pdf">Link to report (PDF)</a></p>

<p>We replicate the findings of <a class="citation" href="#Guo2017-calibration">(Guo, Pleiss, Sun, &amp; Weinberger, 2017)</a> that deep neural networks achieve higher accuracy but worse calibration than shallow nets, and compare different approaches for improving the calibration of neural networks (see figure below). As the baseline approach, we consider the calibration of the softmax outputs from a single network; this is compared to <em>deep ensembles</em>, <em>MC dropout</em>, and <em>concrete dropout</em>. Through experiments on the CIFAR-100 data set, we find that a large neural network can be significantly over-confident about its predictions. We show on a classification problem that an ensemble of deep networks has better classification accuracy and calibration compared to a single network, and that MC dropout and concrete dropout significantly improve the calibration of a large network.</p>

<p><img src="mlp-cw4-fig2.png" alt="Confidence and calibration plots for BigNet. (Figure 2 of our report)" /></p>

<p>(<em>Top row:</em> confidence plots for a deep neural net. The more skewed to the right, the better. <em>Bottom row:</em> corresponding calibration plots. The more close to the diagonal, the better.)</p>

<h2 id="things-i-would-do-differently">Things I would do differently</h2>

<p>With a little more experience behind my back now, I would make the following changes in experiment design and writing the report:</p>
<ul>
  <li><em>Use a validation set.</em> We only used a training set because we trained for minimum error, and we expected <em>calibration</em> to be independent from <em>accuracy</em>, but that is a strong assumption (and likely incorrect, seeing our results in the interim report).</li>
  <li><em>Use better biblography sources.</em> Instead of Google Scholar, I would search <a href="https://dblp.uni-trier.de/">DBLP</a>, where the information is more correct and consistent.</li>
  <li><em>Use pastel colors.</em> I let my collaborator have it his way, but ever since this submission I’m having nightmares in purple and glowing green :D</li>
</ul>

<p>In future work, I would like to test the calibration of a Bayesian neural network, where the weights of the network have a probability distribution instead of a point estimate.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="Guo2017-calibration">Guo, C., Pleiss, G., Sun, Y., &amp; Weinberger, K. Q. (2017). On Calibration of Modern Neural Networks. In D. Precup &amp; Y. W. Teh (Eds.), <i>Proceedings of the 34th International Conference on Machine Learning</i> (Vol. 70, pp. 1321–1330). International Convention Centre, Sydney, Australia: PMLR. Retrieved from http://proceedings.mlr.press/v70/guo17a.html</span></li></ol>

  </div><div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://www.treszkai.com/blog/overconfidence';
      this.page.identifier = 'https://www.treszkai.com/blog/overconfidence';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://treszkai.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/blog/overconfidence" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Laszlo Treszkai</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Laszlo Treszkai</li><li><a class="u-email" href="mailto:laszlo.treszkai@gmail.com">laszlo.treszkai@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/treszkai"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">treszkai</span></a></li><li><a href="https://www.twitter.com/ltreszkai"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">ltreszkai</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <ul class="right-footer-list">
          <li>Explorations in math, AI, ML, et al.
</li>
          <li class="rss-subscribe">Subscribe <a href="/feed.xml">via RSS</a>.</li>
        </ul>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
